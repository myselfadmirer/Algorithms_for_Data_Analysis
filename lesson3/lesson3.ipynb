{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2) \n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-ticks')\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],  # стаж\n",
    "              [500, 700, 750, 600, 1450,        # средняя стоимость занятия\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64) # квалификация репетитора\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1]) # подходит или нет репетитор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def calc_std(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "def calc_mse(x):\n",
    "    return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "def calc_norm(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "X_st = X.copy()\n",
    "X_st = calc_std(X)\n",
    "X_norm = X.copy()\n",
    "X_norm = calc_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "# def calc_logloss(y, y_pred): # Было\n",
    "#     err = np.mean(- y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n",
    "#     return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log (как вариант - np.clip).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = np.mean(- y * np.log(np.clip(y_pred, 1e-8, np.inf)) - (1.0 - y) * np.log(11.0 - np.clip(y_pred, -np.inf, 1 - 1e-8)))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_LR_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations + 1):\n",
    "        \n",
    "        y_pred = sigmoid(np.dot(w, X))\n",
    "        err = calc_logloss(y, y_pred)    \n",
    "    \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Подберите аргументы функции eval_LR_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model2(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    err = 0\n",
    "    err_prev = np.inf\n",
    "    \n",
    "    for i in range(1, iterations + 1):        \n",
    "        \n",
    "        y_pred = sigmoid(np.dot(w, X))\n",
    "        err_prev = calc_logloss(y, y_pred) \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        \n",
    "#         if err > err_prev:\n",
    "# #             print(err)\n",
    "#             return w, err\n",
    "        err_prev = err\n",
    "  \n",
    "        \n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, w, err)\n",
    "    return w, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(1e-1, 1e2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_loglos = []\n",
    "w_pred = []\n",
    "for i in alpha:\n",
    "    w, err = eval_LR_model2(X_norm, y, iterations=1000, alpha=i)\n",
    "    err_loglos.append(err)\n",
    "    w_pred.append(w)\n",
    "\n",
    "err_loglos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_loglos, alpha);\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются веса, которые уже посчитаны функцией eval_LR_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, x):\n",
    "    return sigmoid(np.dot(w, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются веса, которые уже посчитаны функцией eval_LR_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w, x, line=0.5):\n",
    "    calc_pred = list(map(lambda x: 1 if x > line else 0, calc_pred_proba(w, x)))\n",
    "    return calc_pred\n",
    "\n",
    "\n",
    "y_pred = calc_pred(w, X_st)\n",
    "y_pred, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Посчитайте accuracy, матрицу ошибок, precision и recall, а также F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 100.0 - np.mean(np.abs(y_pred - y)*100.0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(len(y)):\n",
    "    if y[i] == y_pred[i]:\n",
    "        if y[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    else:\n",
    "        if y[i] == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "conf_m = np.array([[tp, tn], [fp, fn]])\n",
    "conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=conf_m[0,0]/(conf_m[0,0]+conf_m[0,1])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall=conf_m[0,0]/(conf_m[0,0]+conf_m[1,0])\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1=2*precision*recall/(precision+recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. *Создайте функции eval_LR_model_l1 и eval_LR_model_l2 с применением L1 и L2 регуляризации соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model_l1(X, y, alpha=1e-4, lambda_=1e-6):      \n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    err_prev = np.inf\n",
    "    err = 0  \n",
    "    while np.abs(err_prev - err) >= 1e-7:\n",
    "        y_pred = sigmoid(np.dot(w, X))\n",
    "        err_prev = calc_logloss(y, y_pred) \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T)) + lambda_ * np.sign(w)\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "    return w\n",
    "\n",
    "def eval_LR_model_l2(X, y, alpha=1e-4, lambda_=1e-6):      \n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    err_prev = np.inf\n",
    "    err = 0  \n",
    "    while np.abs(err_prev - err) >= 1e-7:\n",
    "        y_pred = sigmoid(np.dot(w, X))\n",
    "        err_prev = calc_logloss(y, y_pred) \n",
    "        w -= alpha * (1/n * np.dot((y_pred - y), X.T)) + 2 * lambda_ * w\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "    return w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
